# data_process/merge_and_convert_SVEN.py
import os
import json
import argparse
from tqdm import tqdm


def extract_commit_id(link):
    """ä» URL ä¸­æå– commit hash"""
    if not link:
        return "unknown"
    try:
        # å¸¸è§æ ¼å¼: .../commit/e34bcbb...
        if 'commit/' in link:
            return link.split('commit/')[-1].split('/')[0]
        return link.split('/')[-1]
    except:
        return "unknown"


def normalize_cwe(raw_cwe):
    """
    æ ‡å‡†åŒ– CWE ID:
    1. å¼ºåˆ¶å¤§å†™ (cwe-787 -> CWE-787)
    2. ç§»é™¤åˆ—è¡¨æ ¼å¼ (['CWE-787'] -> CWE-787)
    3. å¤„ç†ç©ºå€¼
    """
    if not raw_cwe:
        return "N/A"

    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ª
    if isinstance(raw_cwe, list):
        if len(raw_cwe) > 0:
            raw_cwe = str(raw_cwe[0])
        else:
            return "N/A"

    val = str(raw_cwe).strip().upper()

    # ç®€å•æ¸…æ´—ï¼šç§»é™¤å¯èƒ½å­˜åœ¨çš„å¼•å·æˆ–æ‹¬å·ï¼ˆé’ˆå¯¹ä¹‹å‰çš„ dirty æ•°æ®ï¼‰
    val = val.replace("['", "").replace("']", "").replace('["', "").replace('"]', "")

    if val in ["", "NON", "NONE", "NULL", "N/A"]:
        return "N/A"

    return val


def process_and_merge(input_root, output_file):
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    total_files = 0
    all_jsonl_files = []

    # 1. æ‰«ææ‰€æœ‰æ–‡ä»¶
    print(f"ğŸ” Scanning directory: {input_root}")
    for root, dirs, files in os.walk(input_root):
        for file in files:
            if file.endswith(".jsonl"):
                all_jsonl_files.append(os.path.join(root, file))
                total_files += 1

    print(f"ğŸ“„ Found {total_files} JSONL files. Starting merge & conversion...")

    count = 0
    skipped = 0

    # 2. å¤„ç†å¹¶å†™å…¥
    with open(output_file, 'w', encoding='utf-8') as outfile:
        for file_path in tqdm(all_jsonl_files, desc="Merging"):
            with open(file_path, 'r', encoding='utf-8') as infile:
                for line in infile:
                    line = line.strip()
                    if not line: continue
                    try:
                        raw = json.loads(line)

                        # --- æå–åŸºç¡€ä¿¡æ¯ ---
                        cid = extract_commit_id(raw.get('commit_link', ''))

                        # [ä¿®æ”¹ç‚¹] ç»Ÿä¸€ CWE æ ¼å¼
                        raw_cwe = raw.get('vul_type', 'N/A')
                        cwe = normalize_cwe(raw_cwe)

                        func_name = raw.get('func_name', '')

                        # --- ç”Ÿæˆæ ·æœ¬ 1: æ¼æ´ä»£ç  (Before) ---
                        if raw.get('func_src_before'):
                            entry_vuln = {
                                "commit_id": cid,
                                "func": raw['func_src_before'],
                                "target": 1,  # æ ‡è®°ä¸ºæ¼æ´
                                "cwe": cwe,  # ä½¿ç”¨æ ‡å‡†åŒ–åçš„ CWE
                                "func_name": func_name,
                                "origin_source": "before"
                            }
                            outfile.write(json.dumps(entry_vuln) + "\n")
                            count += 1

                        # --- ç”Ÿæˆæ ·æœ¬ 2: ä¿®å¤ä»£ç  (After) ---
                        if raw.get('func_src_after'):
                            entry_safe = {
                                "commit_id": cid,
                                "func": raw['func_src_after'],
                                "target": 0,  # æ ‡è®°ä¸ºå®‰å…¨
                                "cwe": cwe,  # åŒæ ·æ ‡è®° CWE (è¡¨ç¤ºè¿™æ˜¯è¯¥ CWE çš„ä¿®å¤æ ·æœ¬)
                                "func_name": func_name,
                                "origin_source": "after"
                            }
                            outfile.write(json.dumps(entry_safe) + "\n")
                            count += 1

                    except Exception as e:
                        skipped += 1
                        continue

    print("\n" + "=" * 50)
    print(f"âœ… Merge Complete!")
    print(f"ğŸ“‚ Output File: {output_file}")
    print(f"ğŸ“Š Total Samples Generated: {count}")
    print(f"âš ï¸ Skipped Lines (Errors): {skipped}")
    print("=" * 50 + "\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Merge and convert raw vulnerability datasets to VulnSIL format.")
    parser.add_argument("--input_dir", default="data/data_train_val", help="Root directory of source JSONL files")
    parser.add_argument("--output_file", default="data/eval/SVEN.jsonl",
                        help="Path to the output merged JSONL")

    args = parser.parse_args()

    process_and_merge(args.input_dir, args.output_file)